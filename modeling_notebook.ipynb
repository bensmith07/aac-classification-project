{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d2ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.option_context('display.max_rows', 50)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn as sk\n",
    "\n",
    "import prepare\n",
    "import model\n",
    "\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f168193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "intakes = pd.read_csv('aac_intakes_20220304.csv')\n",
    "outcomes = pd.read_csv('aac_outcomes_20220304.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d1cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.aac_prep(intakes, outcomes)\n",
    "df = prepare.aac_get_dogs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52c33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'outcome_type'\n",
    "positive = 'Adoption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c46af8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53507, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946548e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>n_previous_stays</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>month_intake</th>\n",
       "      <th>fixed</th>\n",
       "      <th>sex</th>\n",
       "      <th>breed_mixed</th>\n",
       "      <th>breed_1</th>\n",
       "      <th>color_1</th>\n",
       "      <th>age_intake</th>\n",
       "      <th>found_in_austin</th>\n",
       "      <th>found_in_travis</th>\n",
       "      <th>found_outside_jurisdiction</th>\n",
       "      <th>found_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A664257_0</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Podengo Pequeno</td>\n",
       "      <td>Black</td>\n",
       "      <td>1460 days</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A664266_0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Chihuahua Shorthair</td>\n",
       "      <td>Buff</td>\n",
       "      <td>365 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A651630_0</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>October</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>Tan</td>\n",
       "      <td>2190 days</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A664269_0</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>October</td>\n",
       "      <td>True</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>Great Pyrenees</td>\n",
       "      <td>White</td>\n",
       "      <td>730 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A664272_0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>October</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Cairn Terrier</td>\n",
       "      <td>Brown</td>\n",
       "      <td>365 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136251</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A852194_0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>February</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>Cane Corso</td>\n",
       "      <td>Blue Cream</td>\n",
       "      <td>120 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136259</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A852246_0</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>February</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>Black</td>\n",
       "      <td>60 days</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136260</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A852245_0</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>February</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>Black</td>\n",
       "      <td>60 days</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136289</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A852403_0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>March</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Maltese</td>\n",
       "      <td>White</td>\n",
       "      <td>180 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136294</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>0</td>\n",
       "      <td>A852467_0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>March</td>\n",
       "      <td>False</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>Miniature Poodle</td>\n",
       "      <td>Black</td>\n",
       "      <td>1460 days</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53507 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            intake_type intake_condition animal_type  n_previous_stays  \\\n",
       "8                 Stray           Normal         Dog                 0   \n",
       "9                 Stray           Normal         Dog                 0   \n",
       "14      Owner Surrender          Injured         Dog                 0   \n",
       "16                Stray           Normal         Dog                 0   \n",
       "24                Stray           Normal         Dog                 0   \n",
       "...                 ...              ...         ...               ...   \n",
       "136251            Stray           Normal         Dog                 0   \n",
       "136259  Owner Surrender           Normal         Dog                 0   \n",
       "136260  Owner Surrender           Normal         Dog                 0   \n",
       "136289  Owner Surrender           Normal         Dog                 0   \n",
       "136294  Owner Surrender           Normal         Dog                 0   \n",
       "\n",
       "          stay_id outcome_type month_intake  fixed     sex  breed_mixed  \\\n",
       "8       A664257_0     Adoption      October  False  female         True   \n",
       "9       A664266_0     Transfer      October  False  female         True   \n",
       "14      A651630_0     Adoption      October   True  female         True   \n",
       "16      A664269_0     Adoption      October   True    male         True   \n",
       "24      A664272_0     Transfer      October   True  female         True   \n",
       "...           ...          ...          ...    ...     ...          ...   \n",
       "136251  A852194_0     Transfer     February  False  female        False   \n",
       "136259  A852246_0     Adoption     February  False  female         True   \n",
       "136260  A852245_0     Adoption     February  False    male         True   \n",
       "136289  A852403_0     Transfer        March  False  female         True   \n",
       "136294  A852467_0     Transfer        March  False  female         True   \n",
       "\n",
       "                    breed_1     color_1 age_intake  found_in_austin  \\\n",
       "8           Podengo Pequeno       Black  1460 days            False   \n",
       "9       Chihuahua Shorthair        Buff   365 days             True   \n",
       "14       Labrador Retriever         Tan  2190 days            False   \n",
       "16           Great Pyrenees       White   730 days             True   \n",
       "24            Cairn Terrier       Brown   365 days             True   \n",
       "...                     ...         ...        ...              ...   \n",
       "136251           Cane Corso  Blue Cream   120 days             True   \n",
       "136259   Labrador Retriever       Black    60 days            False   \n",
       "136260   Labrador Retriever       Black    60 days            False   \n",
       "136289              Maltese       White   180 days             True   \n",
       "136294     Miniature Poodle       Black  1460 days             True   \n",
       "\n",
       "        found_in_travis  found_outside_jurisdiction  found_other  \n",
       "8                  True                       False        False  \n",
       "9                 False                       False        False  \n",
       "14                False                        True        False  \n",
       "16                False                       False        False  \n",
       "24                False                       False        False  \n",
       "...                 ...                         ...          ...  \n",
       "136251            False                       False        False  \n",
       "136259             True                       False        False  \n",
       "136260             True                       False        False  \n",
       "136289            False                       False        False  \n",
       "136294            False                       False        False  \n",
       "\n",
       "[53507 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663bc4c",
   "metadata": {},
   "source": [
    "#### Define all but the top 10 breeds as \"other\" to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26354664",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_breeds = list(df.breed_1.value_counts().head(10).index)\n",
    "df['breed_1_reduced'] = np.where(df.breed_1.isin(top_10_breeds), df.breed_1, 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceca86b",
   "metadata": {},
   "source": [
    "#### Do the same with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf80490",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_colors = list(df.color_1.value_counts().head(10).index)\n",
    "df['color_1_reduced'] = np.where(df.color_1.isin(top_10_colors), df.color_1, 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19af63",
   "metadata": {},
   "source": [
    "### Prep for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e07f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.aac_prep_for_modeling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fa99fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53507, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2950e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5efa81",
   "metadata": {},
   "source": [
    "### Train/Validate/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9857b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t n = 29963\n",
      "validate n = 12842\n",
      "test\t n = 10702\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = prepare.train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f4c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.scale_aac(train, validate, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299127f2",
   "metadata": {},
   "source": [
    "#### establish infrastructure for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38e41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = pd.DataFrame()\n",
    "model_results = pd.DataFrame()\n",
    "model_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425b354",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f50573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Adoption\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f2bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(train,\n",
    "                 validate,\n",
    "                 target,\n",
    "                 positive,\n",
    "                 model_number,\n",
    "                 model_info,\n",
    "                 model_results):\n",
    "    '''\n",
    "    This function takes in the train and validate samples as dataframes, the target variable label, the positive condition label,\n",
    "    an initialized model_number variable, as well as model_info and model_results dataframes dataframes that will be used for \n",
    "    storing information about the models. It then performs the operations necessary for making baseline predictions\n",
    "    on our dataset, and stores information about our baseline model in the model_info and model_results dataframes. \n",
    "    The model_number, model_info, and model_results variables are returned (in that order). \n",
    "    '''\n",
    "\n",
    "    # separate each sample into x (features) and y (target)\n",
    "    x_train = train.drop(columns=target)\n",
    "    y_train = train[target]\n",
    "\n",
    "    x_validate = validate.drop(columns=target)\n",
    "    y_validate = validate[target]\n",
    "\n",
    "\n",
    "    # store baseline metrics\n",
    "\n",
    "    # identify model number\n",
    "    model_number = 'baseline'\n",
    "    #identify model type\n",
    "    model_type = 'baseline'\n",
    "\n",
    "    # store info about the model\n",
    "\n",
    "    # create a dictionary containing model number and model type\n",
    "    dct = {'model_number': model_number,\n",
    "           'model_type': model_type}\n",
    "    # append that dictionary to the model_info dataframe\n",
    "    model_info = model_info.append(dct, ignore_index=True)\n",
    "\n",
    "    # establish baseline predictions for train sample\n",
    "    y_pred = pd.Series([train[target].mode()[0]]).repeat(len(train))\n",
    "\n",
    "    # get metrics\n",
    "\n",
    "    # create dictionaries for each metric type for the train sample and append those dictionaries to the model_results dataframe\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    # establish baseline predictions for validate sample\n",
    "    y_pred = baseline_pred = pd.Series([train[target].mode()[0]]).repeat(len(validate))\n",
    "\n",
    "    # get metrics\n",
    "\n",
    "    # create dictionaries for each metric type for the validate sample and append those dictionaries to the model_results dataframe\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_validate, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    # set the model number to from 'baseline' to 0 \n",
    "    model_number = 0\n",
    "    \n",
    "    return model_number, model_info, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57413263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_info, model_results = run_baseline(train,\n",
    "                                                       validate,\n",
    "                                                       target,\n",
    "                                                       positive,\n",
    "                                                       model_number,\n",
    "                                                       model_info,\n",
    "                                                       model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b0531",
   "metadata": {},
   "source": [
    "### RFE Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9202bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "model_number, model_info, model_results = model.rfe_decision_tree(train,\n",
    "                                                                  validate, \n",
    "                                                                  target, \n",
    "                                                                  positive, \n",
    "                                                                  model_number, \n",
    "                                                                  model_info, \n",
    "                                                                  model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ee2f3",
   "metadata": {},
   "source": [
    "### RFE Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c94618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "model_number, model_info, model_results = model.rfe_random_forest(train,\n",
    "                                                                  validate, \n",
    "                                                                  target, \n",
    "                                                                  positive, \n",
    "                                                                  model_number, \n",
    "                                                                  model_info, \n",
    "                                                                  model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2cc0a",
   "metadata": {},
   "source": [
    "### RFE KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_log_regression(train,\n",
    "                      validate, \n",
    "                      target, \n",
    "                      positive, \n",
    "                      model_number, \n",
    "                      model_info, \n",
    "                      model_results):\n",
    "\n",
    "    # all available features\n",
    "    all_features = [col for col in train.columns if 'enc_' in col or 'scaled_' in col]\n",
    "\n",
    "    # separate each sample into x (features) and y (target) - for RFE\n",
    "    x_train_rfe = train[all_features]\n",
    "    y_train_rfe = train[target]\n",
    "\n",
    "    for n_features in range(2, 6):\n",
    "        for c_value in [.001, .01, .1, 1, 10, 100, 1000]:\n",
    "            \n",
    "                #####################################\n",
    "                ### Recursive Feature Elimination ###\n",
    "                #####################################\n",
    "\n",
    "                # establish a logistic regression classifier\n",
    "                clf = LogisticRegression(C=c_value)\n",
    "\n",
    "                # create the rfe object\n",
    "                rfe = RFE(clf, n_features_to_select=n_features)\n",
    "\n",
    "                # fit the data using RFE\n",
    "                rfe.fit(x_train_rfe, y_train_rfe)\n",
    "\n",
    "                # get list of the column names for the selected features\n",
    "                features = x_train_rfe.iloc[:,rfe.support_].columns.tolist()\n",
    "                \n",
    "                ##################\n",
    "                ### Model Info ###\n",
    "                ##################\n",
    "\n",
    "                print(model_number)\n",
    "\n",
    "                # create a new model number by adding 1 to the previous model number\n",
    "                model_number += 1\n",
    "                # establish the model type\n",
    "                model_type = 'logistic regression'\n",
    "\n",
    "                # store info about the model\n",
    "\n",
    "                # create a dictionary containing the features and hyperparamters used in this model instance\n",
    "                dct = {'model_number': model_number,\n",
    "                       'model_type': model_type,\n",
    "                       'features': features,\n",
    "                       'c_value': c_value}\n",
    "                # append that dictionary to the model_info dataframe\n",
    "                model_info = model_info.append(dct, ignore_index=True)\n",
    "                \n",
    "                ################\n",
    "                ### Modeling ###\n",
    "                ################\n",
    "\n",
    "                # separate each sample into x (features) and y (target)\n",
    "                x_train = train[features]\n",
    "                y_train = train[target]\n",
    "\n",
    "                x_validate = validate[features]\n",
    "                y_validate = validate[target]\n",
    "                \n",
    "                # fit the classifier to the training data\n",
    "                clf = clf.fit(x_train, y_train)\n",
    "                \n",
    "                #####################\n",
    "                ### Model Results ###\n",
    "                #####################\n",
    "\n",
    "                ####### train #######\n",
    "\n",
    "                # create prediction results for the model's performance on the train sample\n",
    "                y_pred = clf.predict(x_train)\n",
    "                sample_type = 'train'\n",
    "\n",
    "                # get metrics\n",
    "\n",
    "                # create dictionaries for each metric type for the train sample and append those dictionaries to the model_results dataframe\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'accuracy',\n",
    "                       'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'precision',\n",
    "                       'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'recall',\n",
    "                       'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'f1_score',\n",
    "                       'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "\n",
    "                ####### validate #######\n",
    "\n",
    "                # create prediction results for the model's performance on the validate sample\n",
    "                y_pred = clf.predict(x_validate)\n",
    "                sample_type = 'validate'\n",
    "\n",
    "                # get metrics\n",
    "\n",
    "                # create dictionaries for each metric type for the validate sample and append those dictionaries to the model_results dataframe\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'f1_score',\n",
    "                       'score': sk.metrics.f1_score(y_validate, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'accuracy',\n",
    "                       'score': sk.metrics.accuracy_score(y_validate, y_pred)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'precision',\n",
    "                       'score': sk.metrics.precision_score(y_validate, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "                dct = {'model_number': model_number, \n",
    "                       'sample_type': sample_type, \n",
    "                       'metric_type': 'recall',\n",
    "                       'score': sk.metrics.recall_score(y_validate, y_pred, pos_label=positive)}\n",
    "                model_results = model_results.append(dct, ignore_index=True) \n",
    "                \n",
    "    return model_number, model_info, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_info, model_results = rfe_log_regression(train,\n",
    "                                                              validate, \n",
    "                                                              target, \n",
    "                                                              positive, \n",
    "                                                              model_number, \n",
    "                                                              model_info, \n",
    "                                                              model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_model_results(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_results(model_results, metric_type='accuracy', n_models=3):\n",
    "    '''\n",
    "    This function takes in the model_results dataframe. This is a dataframe in tidy \n",
    "    data format containing the following data for each model created in the project:\n",
    "    - model number\n",
    "    - metric type (accuracy, precision, recall, f1 score)\n",
    "    - sample type (train, validate)\n",
    "    - score (the score for the given metric and sample types)\n",
    "\n",
    "    The function identifies the {n_models} models with the highest scores for the given metric\n",
    "    type, as measured on the validate sample.\n",
    "\n",
    "    It returns a dataframe of information about those models' performance in the tidy data format\n",
    "    (as described above). \n",
    "\n",
    "    The resulting dataframe can be fed into the display_model_results function for convenient display formatting.\n",
    "    '''\n",
    "    # create an array of model numbers for the best performing models\n",
    "    # by filtering the model_results dataframe for only validate scores for the given metric type\n",
    "    best_models = (model_results[(model_results.metric_type == metric_type) \n",
    "                               & (model_results.sample_type == 'validate')]\n",
    "                                                 # sort by score value in descending order\n",
    "                                                 .sort_values(by='score', \n",
    "                                                              ascending=False)\n",
    "                                                 # take only the model number for the top n_models\n",
    "                                                 .head(n_models)\n",
    "                                                 .model_number\n",
    "                                                 # and take only the values from the resulting dataframe as an array\n",
    "                                                 .values)\n",
    "    # create a dataframe of model_results for the models identified above\n",
    "    # by filtering the model_results dataframe for only the model_numbers in the best_models array\n",
    "    # TODO: make this so that it will return n_models, rather than only 3 models\n",
    "    best_model_results = model_results[(model_results.model_number == best_models[0]) \n",
    "                                     | (model_results.model_number == best_models[1]) \n",
    "                                     | (model_results.model_number == best_models[2])]\n",
    "\n",
    "    return best_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_model_results(get_best_model_results(model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info[model_info.model_number.isin([15, 32, 36])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16524cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_num in [15, 32, 36]:\n",
    "    print(f'Model #{model_num} Features:')\n",
    "    print('-' * 20)\n",
    "    for feature in model_info[model_info.model_number == model_num].features.values[0]:\n",
    "        print(feature)\n",
    "    print()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f58052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
